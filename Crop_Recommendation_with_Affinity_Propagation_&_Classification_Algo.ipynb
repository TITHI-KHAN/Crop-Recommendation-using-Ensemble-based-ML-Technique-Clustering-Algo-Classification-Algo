{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2aJ7qiZRzmvB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score, homogeneity_completeness_v_measure\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Crop_recommendation.csv\")"
      ],
      "metadata": {
        "id": "fSw646MpznVu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s3IsxT2vzom1",
        "outputId": "c7be5da6-f694-4c9f-c1e4-fd49aed71559"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Nitrogen  phosphorus  potassium  temperature   humidity        ph  \\\n",
              "0        90          42         43    20.879744  82.002744  6.502985   \n",
              "1        85          58         41    21.770462  80.319644  7.038096   \n",
              "2        60          55         44    23.004459  82.320763  7.840207   \n",
              "3        74          35         40    26.491096  80.158363  6.980401   \n",
              "4        78          42         42    20.130175  81.604873  7.628473   \n",
              "\n",
              "     rainfall label  Unnamed: 8  Unnamed: 9  \n",
              "0  202.935536  rice         NaN         NaN  \n",
              "1  226.655537  rice         NaN         NaN  \n",
              "2  263.964248  rice         NaN         NaN  \n",
              "3  242.864034  rice         NaN         NaN  \n",
              "4  262.717340  rice         NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db4787b5-5658-4c1c-bd5e-ace55c0a4697\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nitrogen</th>\n",
              "      <th>phosphorus</th>\n",
              "      <th>potassium</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>ph</th>\n",
              "      <th>rainfall</th>\n",
              "      <th>label</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>20.879744</td>\n",
              "      <td>82.002744</td>\n",
              "      <td>6.502985</td>\n",
              "      <td>202.935536</td>\n",
              "      <td>rice</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85</td>\n",
              "      <td>58</td>\n",
              "      <td>41</td>\n",
              "      <td>21.770462</td>\n",
              "      <td>80.319644</td>\n",
              "      <td>7.038096</td>\n",
              "      <td>226.655537</td>\n",
              "      <td>rice</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>55</td>\n",
              "      <td>44</td>\n",
              "      <td>23.004459</td>\n",
              "      <td>82.320763</td>\n",
              "      <td>7.840207</td>\n",
              "      <td>263.964248</td>\n",
              "      <td>rice</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74</td>\n",
              "      <td>35</td>\n",
              "      <td>40</td>\n",
              "      <td>26.491096</td>\n",
              "      <td>80.158363</td>\n",
              "      <td>6.980401</td>\n",
              "      <td>242.864034</td>\n",
              "      <td>rice</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>20.130175</td>\n",
              "      <td>81.604873</td>\n",
              "      <td>7.628473</td>\n",
              "      <td>262.717340</td>\n",
              "      <td>rice</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db4787b5-5658-4c1c-bd5e-ace55c0a4697')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db4787b5-5658-4c1c-bd5e-ace55c0a4697 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db4787b5-5658-4c1c-bd5e-ace55c0a4697');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna(axis=1)"
      ],
      "metadata": {
        "id": "qg8I5SXB1weC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1HvVCHCg2IvD",
        "outputId": "2052eda8-fb11-4f69-fd00-7c6ec3003ec5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Nitrogen  phosphorus  potassium  temperature   humidity        ph  \\\n",
              "0        90          42         43    20.879744  82.002744  6.502985   \n",
              "1        85          58         41    21.770462  80.319644  7.038096   \n",
              "2        60          55         44    23.004459  82.320763  7.840207   \n",
              "3        74          35         40    26.491096  80.158363  6.980401   \n",
              "4        78          42         42    20.130175  81.604873  7.628473   \n",
              "\n",
              "     rainfall label  \n",
              "0  202.935536  rice  \n",
              "1  226.655537  rice  \n",
              "2  263.964248  rice  \n",
              "3  242.864034  rice  \n",
              "4  262.717340  rice  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad63f4f7-4369-45ec-9894-c733cc4442d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nitrogen</th>\n",
              "      <th>phosphorus</th>\n",
              "      <th>potassium</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>ph</th>\n",
              "      <th>rainfall</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>20.879744</td>\n",
              "      <td>82.002744</td>\n",
              "      <td>6.502985</td>\n",
              "      <td>202.935536</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85</td>\n",
              "      <td>58</td>\n",
              "      <td>41</td>\n",
              "      <td>21.770462</td>\n",
              "      <td>80.319644</td>\n",
              "      <td>7.038096</td>\n",
              "      <td>226.655537</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>55</td>\n",
              "      <td>44</td>\n",
              "      <td>23.004459</td>\n",
              "      <td>82.320763</td>\n",
              "      <td>7.840207</td>\n",
              "      <td>263.964248</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74</td>\n",
              "      <td>35</td>\n",
              "      <td>40</td>\n",
              "      <td>26.491096</td>\n",
              "      <td>80.158363</td>\n",
              "      <td>6.980401</td>\n",
              "      <td>242.864034</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>20.130175</td>\n",
              "      <td>81.604873</td>\n",
              "      <td>7.628473</td>\n",
              "      <td>262.717340</td>\n",
              "      <td>rice</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad63f4f7-4369-45ec-9894-c733cc4442d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad63f4f7-4369-45ec-9894-c733cc4442d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad63f4f7-4369-45ec-9894-c733cc4442d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "X_train = train[['Nitrogen', 'phosphorus', 'potassium', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
        "X_test = test[['Nitrogen', 'phosphorus', 'potassium', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
        "y_train = train['label']\n",
        "y_test = test['label']"
      ],
      "metadata": {
        "id": "HOaSzZN3-D9f"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation**"
      ],
      "metadata": {
        "id": "bZ7PZGkEqXPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AffinityPropagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lFb2wFS0khHB",
        "outputId": "750301bd-ef03-4767-a1c0-85794a3d35e9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AffinityPropagation()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AffinityPropagation()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AffinityPropagation</label><div class=\"sk-toggleable__content\"><pre>AffinityPropagation()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AffinityPropagation\n",
        "\n",
        "# Get the predicted cluster labels for the training data\n",
        "train_cluster_labels = affinity_propagation.labels_\n",
        "\n",
        "# Compute evaluation metrics for Affinity Propagation\n",
        "silhouette_avg = silhouette_score(X_train, train_cluster_labels)\n",
        "ari = adjusted_rand_score(y_train, train_cluster_labels)\n",
        "homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y_train, train_cluster_labels)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "print(\"Adjusted Rand Index:\", ari)\n",
        "print(\"Homogeneity:\", homogeneity)\n",
        "print(\"Completeness:\", completeness)\n",
        "print(\"V-measure:\", v_measure)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwzHS9Ylkyom",
        "outputId": "3029ca0a-7dc4-41ac-8427-1ff982d30d74"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.368500876146879\n",
            "Adjusted Rand Index: 0.7451747561934313\n",
            "Homogeneity: 0.9429264229511191\n",
            "Completeness: 0.8386322623658429\n",
            "V-measure: 0.8877266023749769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted cluster labels for the training and test data\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)"
      ],
      "metadata": {
        "id": "dqeWHmxElfLZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier**"
      ],
      "metadata": {
        "id": "xPQhsL5EqL99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Decision Tree classifier on the original features\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Create an ensemble model with Decision Tree classifier and cluster labels as features\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('decision_tree', decision_tree)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Predict crop labels using the ensemble model\n",
        "ensemble_predictions = ensemble_model.predict(X_test_with_clusters)\n"
      ],
      "metadata": {
        "id": "LJLpQ-gYlhe9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, ensemble_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "classification_rep = classification_report(y_test, ensemble_predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "precision = precision_score(y_test, ensemble_predictions, average=None)\n",
        "print(\"Precision for each class:\")\n",
        "print(precision)\n",
        "\n",
        "recall = recall_score(y_test, ensemble_predictions, average=None)\n",
        "print(\"Recall for each class:\")\n",
        "print(recall)\n",
        "\n",
        "f1 = f1_score(y_test, ensemble_predictions, average='weighted')\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGqT_yFFnBdL",
        "outputId": "e49c20d2-d27b-41a3-edf2-944d50948d21"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9863636363636363\n",
            "Confusion Matrix:\n",
            "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  1  0  0 22  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0 17  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        23\n",
            "      banana       1.00      1.00      1.00        21\n",
            "   blackgram       0.95      1.00      0.98        20\n",
            "    chickpea       1.00      1.00      1.00        26\n",
            "     coconut       1.00      1.00      1.00        27\n",
            "      coffee       1.00      1.00      1.00        17\n",
            "      cotton       1.00      1.00      1.00        17\n",
            "      grapes       1.00      1.00      1.00        14\n",
            "        jute       0.92      0.96      0.94        23\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       0.92      1.00      0.96        11\n",
            "       maize       1.00      0.95      0.98        21\n",
            "       mango       1.00      1.00      1.00        19\n",
            "   mothbeans       1.00      0.92      0.96        24\n",
            "    mungbean       0.95      1.00      0.97        19\n",
            "   muskmelon       1.00      1.00      1.00        17\n",
            "      orange       1.00      1.00      1.00        14\n",
            "      papaya       1.00      1.00      1.00        23\n",
            "  pigeonpeas       1.00      1.00      1.00        23\n",
            " pomegranate       1.00      1.00      1.00        23\n",
            "        rice       0.94      0.89      0.92        19\n",
            "  watermelon       1.00      1.00      1.00        19\n",
            "\n",
            "    accuracy                           0.99       440\n",
            "   macro avg       0.99      0.99      0.99       440\n",
            "weighted avg       0.99      0.99      0.99       440\n",
            "\n",
            "Precision for each class:\n",
            "[1.         1.         0.95238095 1.         1.         1.\n",
            " 1.         1.         0.91666667 1.         0.91666667 1.\n",
            " 1.         1.         0.95       1.         1.         1.\n",
            " 1.         1.         0.94444444 1.        ]\n",
            "Recall for each class:\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.95652174 1.         1.         0.95238095\n",
            " 1.         0.91666667 1.         1.         1.         1.\n",
            " 1.         1.         0.89473684 1.        ]\n",
            "F1-score: 0.9863237630351415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Random Forest Classifier, Voting Classifier**"
      ],
      "metadata": {
        "id": "0KAoXkUHqcuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest classifier\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Create an ensemble model with Random Forest and cluster labels as features\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('random_forest', random_forest)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Predict crop labels using the ensemble model\n",
        "ensemble_predictions = ensemble_model.predict(X_test_with_clusters)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, ensemble_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, ensemble_predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Precision for each class\n",
        "precision = precision_score(y_test, ensemble_predictions, average=None)\n",
        "print(\"Precision for each class:\")\n",
        "print(precision)\n",
        "\n",
        "# Recall for each class\n",
        "recall = recall_score(y_test, ensemble_predictions, average=None)\n",
        "print(\"Recall for each class:\")\n",
        "print(recall)\n",
        "\n",
        "# F1-score\n",
        "f1 = f1_score(y_test, ensemble_predictions, average='weighted')\n",
        "print(\"F1-score:\", f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRP8Cbl7pWeZ",
        "outputId": "7938abd1-472f-45e5-e573-d9688fe2dbdb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9840909090909091\n",
            "Confusion Matrix:\n",
            "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0 22  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  1  0  0 22  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0 17  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        23\n",
            "      banana       1.00      1.00      1.00        21\n",
            "   blackgram       0.87      1.00      0.93        20\n",
            "    chickpea       1.00      1.00      1.00        26\n",
            "     coconut       1.00      1.00      1.00        27\n",
            "      coffee       0.94      1.00      0.97        17\n",
            "      cotton       1.00      1.00      1.00        17\n",
            "      grapes       1.00      1.00      1.00        14\n",
            "        jute       0.92      0.96      0.94        23\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       0.92      1.00      0.96        11\n",
            "       maize       1.00      1.00      1.00        21\n",
            "       mango       1.00      1.00      1.00        19\n",
            "   mothbeans       1.00      0.92      0.96        24\n",
            "    mungbean       1.00      1.00      1.00        19\n",
            "   muskmelon       1.00      1.00      1.00        17\n",
            "      orange       1.00      1.00      1.00        14\n",
            "      papaya       1.00      1.00      1.00        23\n",
            "  pigeonpeas       1.00      0.91      0.95        23\n",
            " pomegranate       1.00      1.00      1.00        23\n",
            "        rice       1.00      0.89      0.94        19\n",
            "  watermelon       1.00      1.00      1.00        19\n",
            "\n",
            "    accuracy                           0.98       440\n",
            "   macro avg       0.98      0.99      0.98       440\n",
            "weighted avg       0.99      0.98      0.98       440\n",
            "\n",
            "Precision for each class:\n",
            "[1.         1.         0.86956522 1.         1.         0.94444444\n",
            " 1.         1.         0.91666667 1.         0.91666667 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.        ]\n",
            "Recall for each class:\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.95652174 1.         1.         1.\n",
            " 1.         0.91666667 1.         1.         1.         1.\n",
            " 0.91304348 1.         0.89473684 1.        ]\n",
            "F1-score: 0.9841547784982921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Random Forest Classifier, Voting Classifier, Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "gu0rgOHPqmbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an SVM classifier\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Create an ensemble model with Random Forest, SVM, and cluster labels as features\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('random_forest', random_forest), ('svm', svm)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Predict crop labels using the ensemble model\n",
        "ensemble_predictions = ensemble_model.predict(X_test_with_clusters)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, ensemble_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, ensemble_predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Precision for each class\n",
        "precision = precision_score(y_test, ensemble_predictions, average=None)\n",
        "print(\"Precision for each class:\")\n",
        "print(precision)\n",
        "\n",
        "# Recall for each class\n",
        "recall = recall_score(y_test, ensemble_predictions, average=None)\n",
        "print(\"Recall for each class:\")\n",
        "print(recall)\n",
        "\n",
        "# F1-score\n",
        "f1 = f1_score(y_test, ensemble_predictions, average='weighted')\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lgmhDvpqDsK",
        "outputId": "4143562d-eb3b-4869-f1cc-2ca4191b49c2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9590909090909091\n",
            "Confusion Matrix:\n",
            "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0 22  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  3  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  3  0  0 20  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        23\n",
            "      banana       1.00      1.00      1.00        21\n",
            "   blackgram       0.87      1.00      0.93        20\n",
            "    chickpea       1.00      1.00      1.00        26\n",
            "     coconut       1.00      1.00      1.00        27\n",
            "      coffee       0.94      1.00      0.97        17\n",
            "      cotton       0.85      1.00      0.92        17\n",
            "      grapes       1.00      1.00      1.00        14\n",
            "        jute       0.76      0.96      0.85        23\n",
            " kidneybeans       0.95      1.00      0.98        20\n",
            "      lentil       0.79      1.00      0.88        11\n",
            "       maize       1.00      0.86      0.92        21\n",
            "       mango       1.00      1.00      1.00        19\n",
            "   mothbeans       1.00      0.83      0.91        24\n",
            "    mungbean       1.00      1.00      1.00        19\n",
            "   muskmelon       1.00      1.00      1.00        17\n",
            "      orange       1.00      1.00      1.00        14\n",
            "      papaya       1.00      1.00      1.00        23\n",
            "  pigeonpeas       1.00      0.87      0.93        23\n",
            " pomegranate       1.00      1.00      1.00        23\n",
            "        rice       1.00      0.63      0.77        19\n",
            "  watermelon       1.00      1.00      1.00        19\n",
            "\n",
            "    accuracy                           0.96       440\n",
            "   macro avg       0.96      0.96      0.96       440\n",
            "weighted avg       0.97      0.96      0.96       440\n",
            "\n",
            "Precision for each class:\n",
            "[1.         1.         0.86956522 1.         1.         0.94444444\n",
            " 0.85       1.         0.75862069 0.95238095 0.78571429 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.        ]\n",
            "Recall for each class:\n",
            "[1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.95652174 1.         1.         0.85714286\n",
            " 1.         0.83333333 1.         1.         1.         1.\n",
            " 0.86956522 1.         0.63157895 1.        ]\n",
            "F1-score: 0.9584138989580661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Classifier**"
      ],
      "metadata": {
        "id": "st31MIYwrchN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define and train the Gradient Boosting model\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = gradient_boosting.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goloW-g9rctm",
        "outputId": "ce175995-cac7-4a66-a154-9fafed5e6ca0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9818181818181818\n",
            "Precision: 0.9842712842712842\n",
            "Recall: 0.9818181818181818\n",
            "F1-score: 0.9818514668069125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Random Forest Classifier, Voting Classifier, Support Vector Machines (SVM), Gradient Boosting Classifier**"
      ],
      "metadata": {
        "id": "3p1Y2I3WtB63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
        "gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest Classifier\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Support Vector Machines (SVM)\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gradient_boosting', gradient_boosting),\n",
        "        ('random_forest', random_forest),\n",
        "        ('svm', svm)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF0RSNA-tCDg",
        "outputId": "5fafd66b-6d99-4db9-f7d4-393e73872186"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9795454545454545\n",
            "Precision: 0.9814221563460694\n",
            "Recall: 0.9795454545454545\n",
            "F1-score: 0.9795649902233715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, Gradient Boosting Classifier**"
      ],
      "metadata": {
        "id": "sM4fxLXXunES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('decision_tree', decision_tree),\n",
        "        ('gradient_boosting', gradient_boosting)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
        "gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Train the Voting Classifier on the combined features\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhOwsu1LunND",
        "outputId": "2c9b21d0-b8d7-4ce7-9b6e-a87a87f16ddb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9840909090909091\n",
            "Precision: 0.9856065020837748\n",
            "Recall: 0.9840909090909091\n",
            "F1-score: 0.9840457379648412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation and Gradient Boosting Classifier**"
      ],
      "metadata": {
        "id": "_7d4SDM5vp6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Concatenate cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
        "gradient_boosting.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = gradient_boosting.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P7E5xZ1vqHL",
        "outputId": "eb519c3d-f3a1-4554-d31a-6be808255f86"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9840909090909091\n",
            "Precision: 0.9856065020837748\n",
            "Recall: 0.9840909090909091\n",
            "F1-score: 0.9840457379648412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Gradient Boosting Classifier, and Voting Classifier**"
      ],
      "metadata": {
        "id": "BgvqtGR0wWu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Concatenate cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
        "gradient_boosting.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gradient_boosting', gradient_boosting)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5eQSnMXwW0q",
        "outputId": "31720393-f0bb-40ae-efde-eb3670d6bf83"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9840909090909091\n",
            "Precision: 0.9856065020837748\n",
            "Recall: 0.9840909090909091\n",
            "F1-score: 0.9840457379648412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, and K-Nearest Neighbors (KNN) Classifier**"
      ],
      "metadata": {
        "id": "eVT_JMfsx5BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Affinity Propagation for clustering\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "\n",
        "# Get the cluster labels for the training data\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) Classifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('decision_tree', decision_tree),\n",
        "        ('knn', knn)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "95ivgsAyx5Lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357d17e5-5cfa-4c69-cda4-cc4756c03ed5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9613636363636363\n",
            "Precision: 0.9662698010889048\n",
            "Recall: 0.9613636363636363\n",
            "F1-score: 0.9610867799689151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, and Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "4hs34bVB4N6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Affinity Propagation for clustering\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "\n",
        "# Get the cluster labels for the training data\n",
        "train_cluster_labels = affinity_propagation.predict(X_train)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Naive Bayes Classifier\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('decision_tree', decision_tree),\n",
        "        ('naive_bayes', naive_bayes)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "id": "eGG958D_4OET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1066c73-58a4-4929-bc92-5ac174ef099c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9863636363636363\n",
            "Precision: 0.9874868187368187\n",
            "Recall: 0.9863636363636363\n",
            "F1-score: 0.9863322125173449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, and Logistic Regression**"
      ],
      "metadata": {
        "id": "TAC52a6p7M6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Affinity Propagation for clustering\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train_scaled)\n",
        "\n",
        "# Get the cluster labels for the training data\n",
        "train_cluster_labels = affinity_propagation.predict(X_train_scaled)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test_scaled)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Logistic Regression Classifier\n",
        "logistic_regression = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logistic_regression.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train_scaled, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test_scaled, test_cluster_labels))\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('decision_tree', decision_tree),\n",
        "        ('logistic_regression', logistic_regression)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "id": "oYyyy-rf7NIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4711fa07-1344-42a8-faba-1812c170737c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9590909090909091\n",
            "Precision: 0.9637169833624873\n",
            "Recall: 0.9590909090909091\n",
            "F1-score: 0.9584668535939738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Support Vector Machines (SVM), and Voting Classifier**"
      ],
      "metadata": {
        "id": "FN7V4cH68Q3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Affinity Propagation for clustering\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train_scaled)\n",
        "\n",
        "# Get the cluster labels for the training data\n",
        "train_cluster_labels = affinity_propagation.predict(X_train_scaled)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test_scaled)\n",
        "\n",
        "# Support Vector Machines (SVM) Classifier\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train_scaled, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test_scaled, test_cluster_labels))\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', svm_classifier)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "id": "29iRCadh8Q_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7ef924-67cc-4126-9b8b-52ca09a5fe20"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45227272727272727\n",
            "Precision: 0.4043712784824215\n",
            "Recall: 0.45227272727272727\n",
            "F1-score: 0.35740599378471605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, and regularization methods like L1 or L2 regularization**"
      ],
      "metadata": {
        "id": "8hBXWqC38myS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Affinity Propagation for clustering\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train_scaled)\n",
        "\n",
        "# Get the cluster labels for the training data\n",
        "train_cluster_labels = affinity_propagation.predict(X_train_scaled)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test_scaled)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_train_with_clusters = np.column_stack((X_train_scaled, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test_scaled, test_cluster_labels))\n",
        "\n",
        "# Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('decision_tree', decision_tree)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train_with_clusters, y_train)\n",
        "\n",
        "# Regularization using Logistic Regression with L1 or L2 regularization\n",
        "logistic_regression = LogisticRegression(penalty='l2', random_state=42)\n",
        "logistic_regression.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_voting = voting_classifier.predict(X_test_with_clusters)\n",
        "y_pred_logistic = logistic_regression.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the Voting Classifier\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
        "precision_voting = precision_score(y_test, y_pred_voting, average='weighted')\n",
        "recall_voting = recall_score(y_test, y_pred_voting, average='weighted')\n",
        "f1_voting = f1_score(y_test, y_pred_voting, average='weighted')\n",
        "\n",
        "print(\"Voting Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_voting)\n",
        "print(\"Precision:\", precision_voting)\n",
        "print(\"Recall:\", recall_voting)\n",
        "print(\"F1-score:\", f1_voting)\n",
        "\n",
        "# Evaluate the Logistic Regression\n",
        "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "precision_logistic = precision_score(y_test, y_pred_logistic, average='weighted')\n",
        "recall_logistic = recall_score(y_test, y_pred_logistic, average='weighted')\n",
        "f1_logistic = f1_score(y_test, y_pred_logistic, average='weighted')\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Accuracy:\", accuracy_logistic)\n",
        "print(\"Precision:\", precision_logistic)\n",
        "print(\"Recall:\", recall_logistic)\n",
        "print(\"F1-score:\", f1_logistic)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_voting = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Calculate the overall accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "print(\"Overall Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "U8LosNYQ8m5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8743798c-eda8-4d34-9b24-e2fa4c20852a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier:\n",
            "Accuracy: 0.9886363636363636\n",
            "Precision: 0.9889971139971141\n",
            "Recall: 0.9886363636363636\n",
            "F1-score: 0.988595068964984\n",
            "Logistic Regression:\n",
            "Accuracy: 0.9636363636363636\n",
            "Precision: 0.9644420567548909\n",
            "Recall: 0.9636363636363636\n",
            "F1-score: 0.9635115059268676\n",
            "Overall Accuracy: 0.9886363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, Random Forest**"
      ],
      "metadata": {
        "id": "ldXVc3he9fcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.labels_\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train[:, :-1], y_train)  # Exclude the last column which represents the cluster labels\n",
        "\n",
        "# Voting Classifier with Decision Tree and Random Forest\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('decision_tree', decision_tree), ('random_forest', RandomForestClassifier(random_state=42))],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with original features\n",
        "X_train_with_clusters = np.column_stack((X_train[:, :-1], train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test[:, :-1], test_cluster_labels))\n",
        "\n",
        "# Make predictions on the test set using the ensemble model\n",
        "ensemble_predictions = voting_classifier.predict(X_test_with_clusters)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "id": "8L7GIHPE9fjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b83be02-01e7-4126-92a6-76901404d85a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45227272727272727\n",
            "Precision: 0.4043712784824215\n",
            "Recall: 0.45227272727272727\n",
            "F1-score: 0.35740599378471605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, XGBoost**"
      ],
      "metadata": {
        "id": "zVnq1jXs9hll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.labels_\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Voting Classifier with Decision Tree and XGBoost\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('decision_tree', decision_tree), ('xgboost', XGBClassifier(random_state=42))],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Select the columns for training and prediction\n",
        "train_columns = list(range(X_train.shape[1]))  # Include all columns\n",
        "test_columns = list(range(X_test.shape[1]))  # Include all columns\n",
        "\n",
        "# Make predictions on the test set using the ensemble model\n",
        "ensemble_predictions = voting_classifier.predict(X_test_with_clusters[:, test_columns])\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SebXuwC-9hxQ",
        "outputId": "c2959730-e0ee-4574-935f-59d2efba0b07"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45227272727272727\n",
            "Precision: 0.4043712784824215\n",
            "Recall: 0.45227272727272727\n",
            "F1-score: 0.35740599378471605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, LightGBM**"
      ],
      "metadata": {
        "id": "WyBFvioq9o-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.labels_\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Voting Classifier with Decision Tree and LightGBM\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('decision_tree', decision_tree), ('lightgbm', lgb.LGBMClassifier(random_state=42))],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Select the columns for training and prediction\n",
        "train_columns = list(range(X_train.shape[1]))  # Include all columns\n",
        "test_columns = list(range(X_test.shape[1]))  # Include all columns\n",
        "\n",
        "# Make predictions on the test set using the ensemble model\n",
        "ensemble_predictions = voting_classifier.predict(X_test_with_clusters[:, test_columns])\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4wiyQp19trZ",
        "outputId": "a5724f90-9712-47e3-c98f-fa63327bbde1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45227272727272727\n",
            "Precision: 0.4043712784824215\n",
            "Recall: 0.45227272727272727\n",
            "F1-score: 0.35740599378471605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier,\n",
        " AdaBoost**"
      ],
      "metadata": {
        "id": "cQW_fJTS9uG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.labels_\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Voting Classifier with Decision Tree and AdaBoost\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('decision_tree', decision_tree), ('adaboost', AdaBoostClassifier(random_state=42))],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Select the columns for training and prediction\n",
        "train_columns = list(range(X_train.shape[1]))  # Include all columns\n",
        "test_columns = list(range(X_test.shape[1]))  # Include all columns\n",
        "\n",
        "# Make predictions on the test set using the ensemble model\n",
        "ensemble_predictions = voting_classifier.predict(X_test_with_clusters[:, test_columns])\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neUWcx1f9uO9",
        "outputId": "78189b29-fb75-4df7-f974-d7a8f13b141d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45227272727272727\n",
            "Precision: 0.4043712784824215\n",
            "Recall: 0.45227272727272727\n",
            "F1-score: 0.35740599378471605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, regularization methods like L1 or L2 regularization, Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "hhKXyGEBBS9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Affinity Propagation\n",
        "affinity_propagation = AffinityPropagation()\n",
        "affinity_propagation.fit(X_train)\n",
        "train_cluster_labels = affinity_propagation.labels_\n",
        "test_cluster_labels = affinity_propagation.predict(X_test)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Voting Classifier with Decision Tree, Logistic Regression, and Naive Bayes\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('decision_tree', decision_tree),\n",
        "                ('logistic_regression', LogisticRegression(penalty='l2', random_state=42)),\n",
        "                ('naive_bayes', MultinomialNB())],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Concatenate cluster labels with original features\n",
        "X_train_with_clusters = np.column_stack((X_train, train_cluster_labels))\n",
        "X_test_with_clusters = np.column_stack((X_test, test_cluster_labels))\n",
        "\n",
        "# Select the columns for training and prediction\n",
        "train_columns = list(range(X_train.shape[1]))  # Include all columns\n",
        "test_columns = list(range(X_test.shape[1]))  # Include all columns\n",
        "\n",
        "# Make predictions on the test set using the ensemble model\n",
        "ensemble_predictions = voting_classifier.predict(X_test_with_clusters[:, test_columns])\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHk4E8bnBTGE",
        "outputId": "b68ea906-4b6d-4292-d60f-ecc739619255"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.45227272727272727\n",
            "Precision: 0.4043712784824215\n",
            "Recall: 0.45227272727272727\n",
            "F1-score: 0.35740599378471605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Affinity Propagation, Decision Tree Classifier, Voting Classifier, regularization methods like L1 or L2 regularization, Naive Bayes Classifier, k-fold cross-validation**"
      ],
      "metadata": {
        "id": "T-rxsXGpC97G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Preprocess the data\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "X_train = train[['Nitrogen', 'phosphorus', 'potassium', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
        "X_test = test[['Nitrogen', 'phosphorus', 'potassium', 'temperature', 'humidity', 'ph', 'rainfall']].values\n",
        "y_train = train['label']\n",
        "y_test = test['label']\n",
        "\n",
        "# Step 2: Perform clustering with Affinity Propagation\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "affinity_propagation = AffinityPropagation()\n",
        "cluster_labels = affinity_propagation.fit_predict(X_train_scaled)\n",
        "\n",
        "# Step 3: Train the ensemble model\n",
        "# Prepare features and labels based on cluster labels\n",
        "X_train_clustered = pd.DataFrame(X_train, columns=['Nitrogen', 'phosphorus', 'potassium', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
        "X_train_clustered['cluster'] = cluster_labels\n",
        "\n",
        "# Define the ensemble models\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "voting_classifier = VotingClassifier(estimators=[('lr', LogisticRegression()), ('nb', GaussianNB())])\n",
        "\n",
        "# Fit the models to the training data\n",
        "decision_tree.fit(X_train_clustered, y_train)\n",
        "voting_classifier.fit(X_train_clustered, y_train)\n",
        "\n",
        "# Step 4: Evaluate the ensemble model\n",
        "kfold = 5\n",
        "accuracy_decision_tree = cross_val_score(decision_tree, X_train_clustered, y_train, cv=kfold).mean()\n",
        "accuracy_voting_classifier = cross_val_score(voting_classifier, X_train_clustered, y_train, cv=kfold).mean()\n",
        "\n",
        "# Step 5: Make crop recommendations\n",
        "crop_recommendations = {}\n",
        "\n",
        "# Perform clustering on the test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "test_cluster_labels = affinity_propagation.predict(X_test_scaled)\n",
        "\n",
        "# Prepare test data with cluster labels\n",
        "X_test_clustered = pd.DataFrame(X_test, columns=['Nitrogen', 'phosphorus', 'potassium', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
        "X_test_clustered['cluster'] = test_cluster_labels\n",
        "\n",
        "# Predict crop labels for test data using the ensemble models\n",
        "decision_tree_predictions = decision_tree.predict(X_test_clustered)\n",
        "voting_classifier_predictions = voting_classifier.predict(X_test_clustered)\n",
        "\n",
        "# Calculate accuracy of the ensemble models on the test data\n",
        "accuracy_decision_tree_test = accuracy_score(y_test, decision_tree_predictions)\n",
        "accuracy_voting_classifier_test = accuracy_score(y_test, voting_classifier_predictions)\n",
        "\n",
        "# Calculate the overall accuracy using majority voting\n",
        "ensemble_predictions = pd.DataFrame({'Decision Tree': decision_tree_predictions, 'Voting Classifier': voting_classifier_predictions})\n",
        "ensemble_predictions['Majority Vote'] = ensemble_predictions.mode(axis=1)[0]\n",
        "accuracy_ensemble = accuracy_score(y_test, ensemble_predictions['Majority Vote'])\n",
        "\n",
        "print(\"Accuracy (Decision Tree Classifier):\", accuracy_decision_tree_test)\n",
        "print(\"Accuracy (Voting Classifier):\", accuracy_voting_classifier_test)\n",
        "print(\"Overall Accuracy (Ensemble):\", accuracy_ensemble)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3IHcR2zC-CM",
        "outputId": "67f4a117-9707-4988-a71e-fa3f32f4df8f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Decision Tree Classifier): 0.9863636363636363\n",
            "Accuracy (Voting Classifier): 0.9613636363636363\n",
            "Overall Accuracy (Ensemble): 0.9636363636363636\n"
          ]
        }
      ]
    }
  ]
}